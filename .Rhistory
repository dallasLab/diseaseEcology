trainable[,2:3]
trainable$presence==1
trainable[trainable$presence==1,2:3]
trainable[trainable$presence==0,2:3]
e.mx.l <- ENMevaluate(occs = trainable[trainable$presence==1,2:3], envs = env2, bg = trainable[trainable$presence==0,2:3],
algorithm = 'maxnet', partitions = 'block',
tune.args = list(fc = "L", rm = 1:2))
env2
load("dv_data.RData")
train2 <- dplyr::filter(train, is.na(wc2.1_5m_bio_1)==FALSE)
table(is.na(train2[,(3:22)]))
PCA <- prcomp(train2[,(3:22)],scale=TRUE)
summary(PCA)
train3 <- cbind(train2, PCA$x[,1:10])
train3$species <- "D. variabilis"
colnames(train3)
trainable <- dplyr::select(train3, species, x,y, presence, PC1, PC2, PC3, PC4, PC5, PC6, PC7, PC8, PC9, PC10)
write.table(trainable, "DV_TrainingPreds.txt")
maps::map()
with(train3[which(train3$presence==0),],
points(y=y, x=x,
pch=16, col=1))
with(train3[which(train3$presence==1),],
points(y=y, x=x,
pch=16, col='red'))
env2
env2
knitr::opts_chunk$set(echo = TRUE)
library(rgbif)
library(maps)
library(terra)
library(raster)
load("dv_data.RData")
train2 <- dplyr::filter(train, is.na(wc2.1_5m_bio_1)==FALSE)
table(is.na(train2[,(3:22)]))
PCA <- prcomp(train2[,(3:22)],scale=TRUE)
summary(PCA)
train3 <- cbind(train2, PCA$x[,1:10])
train3$species <- "D. variabilis"
colnames(train3)
trainable <- dplyr::select(train3, species, x,y, presence, PC1, PC2, PC3, PC4, PC5, PC6, PC7, PC8, PC9, PC10)
write.table(trainable, "DV_TrainingPreds.txt")
maps::map()
with(train3[which(train3$presence==0),],
points(y=y, x=x,
pch=16, col=1))
with(train3[which(train3$presence==1),],
points(y=y, x=x,
pch=16, col='red'))
PCA <- prcomp(train2[,(3:21)],scale=TRUE)
z <- scale(test[,(3:21)], PCA$center, PCA$scale) %*% PCA$rotation
testable <- cbind(test,data.frame(z))
# Training model
logistic_model <- glm(presence ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10,
data = trainable,
family = "binomial")
testable$preds <- predict(logistic_model,
testable, type = "response")
colnames(train2)
x <- pROC::roc(response=testable$presence, predictor=testable$preds)
#table(testable$presence, testable$preds)
#predict_reg
hist(testable$presence-testable$pred)
#pROC::roc()
summary(logistic_model)
plot(x=c(0,1),y=c(0,1000))
for(threshold in seq(0.1,0.9, by=0.1)){
temp <- testable$preds
temp[temp<threshold] <- 0
temp[temp>threshold] <- 1
print(sum(sqrt(temp-testable$presence)))
}
library(pROC)
pROC::roc(response=testable$presence, predictor=testable$preds)
# ROC-AUC Curve
ROCPred <- prediction(predict_reg, test_reg$vs)
env2
class(env2)
load("~/Documents/Coding_Challenges/dv_data.RData")
load("~/Documents/Coding_Challenges/dv_data.RData")
env2
env2
envs <- raster::stack(env2)
load("~/Documents/Coding_Challenges/dv (1).RData")
envs <- raster::stack(env2)
e.mx.l <- ENMevaluate(occs = trainable[trainable$presence==1,2:3], envs = env2, bg = trainable[trainable$presence==0,2:3],
algorithm = 'maxnet', partitions = 'block',
tune.args = list(fc = "L", rm = 1:2))
library(ENMeval)
library(raster)
e.mx.l <- ENMevaluate(occs = trainable[trainable$presence==1,2:3], envs = env2, bg = trainable[trainable$presence==0,2:3],
algorithm = 'maxnet', partitions = 'block',
tune.args = list(fc = "L", rm = 1:2))
class(env2)
class(env)
e.mx.l <- ENMevaluate(occs = trainable[trainable$presence==1,2:3], envs = env, bg = trainable[trainable$presence==0,2:3],
algorithm = 'maxnet', partitions = 'block',
tune.args = list(fc = "L", rm = 1:2))
e.mx.l
e.mx.l <- ENMevaluate(occs = trainable[trainable$presence==1,2:3], envs = env, bg = trainable[trainable$presence==0,2:3],
algorithm = 'maxnet', partitions = 'block',
tune.args = list(fc = "L", rm = 1:2))
plot(env$bio1)
env <- geodata::worldclim_global('bio', 5, '.')
env
plot(env$bio1)
e.mx.l <- ENMevaluate(occs = trainable[trainable$presence==1,2:3], envs = env, bg = trainable[trainable$presence==0,2:3],
algorithm = 'maxnet', partitions = 'block',
tune.args = list(fc = "L", rm = 1:2))
e.mx.l
evalplot.stats(e = e.mx, stats = "or.mtp", color = "fc", x.var = "rm")
str(e.mx.l)
e.mx.l@predictions
e.mx.l@results
save(e.mx.l, file="ENM.RData")
knitr::opts_chunk$set(echo = TRUE)
t.test(dat$Geranium_abund[dat$Disturbance=="Low"], dat$Geranium_abund[dat$Disturbance=="High"])
dat <- read.csv(file="Pop_Distribution_S23.csv")
dat <- dplyr::filter(dat, is.na(Quadrat.Number)==FALSE)
dat <- dat[,1:13]
colnames(dat) <-  c("Quadrat", "Canopy", "Temp","PAR", "Geranium_abund","Geranium_cov", "Tredescantia_abund","Tredescantia_cov","Shep_abund","Shep_cov","Plantago_abund","Plantago_cov","Disturbance")
datwide <- read.csv(file="Pop_Distribution_Wide_S23.csv")
t.test(dat$Geranium_abund[dat$Disturbance=="Low"], dat$Geranium_abund[dat$Disturbance=="High"])
t.test(dat$Geranium_cov[dat$Disturbance=="Low"], dat$Geranium_cov[dat$Disturbance=="High"])
t.test(dat$Tredescantia_abund[dat$Disturbance=="Low"], dat$Tredescantia_abund[dat$Disturbance=="High"])
t.test(dat$Tredescantia_cov[dat$Disturbance=="Low"], dat$Tredescantia_cov[dat$Disturbance=="High"])
t.test(dat$Shep_abund[dat$Disturbance=="Low"], dat$Shep_abund[dat$Disturbance=="High"])
t.test(dat$Shep_cov[dat$Disturbance=="Low"], dat$Shep_cov[dat$Disturbance=="High"])
t.test(dat$Plantago_abund[dat$Disturbance=="Low"], dat$Plantago_abund[dat$Disturbance=="High"])
t.test(dat$Plantago_cov[dat$Disturbance=="Low"], dat$Plantago_cov[dat$Disturbance=="High"])
sqrt(dat$Geranium_cov)
asin(sqrt(dat$Geranium_cov))
sqrt(dat$Geranium_cov)
asin(sqrt(x))
asin(sqrt(dat$Geranium_cov))
dat$Geranium_cov
asin(sqrt(dat$Geranium_cov/100))
asin(sqrt(dat$Geranium_cov/100))
plot(x=dat$Geranium_cov/100, y=asin(sqrt(dat$Geranium_cov/100)))
boxplot(dat$Geranium_abund[dat$Disturbance=="Low"],
dat$Geranium_abund[dat$Disturbance=="High"],
dat$Tredescantia_abund[dat$Disturbance=="Low"],
dat$Tredescantia_abund[dat$Disturbance=="High"],
dat$Shep_abund[dat$Disturbance=="Low"],
dat$Shep_abund[dat$Disturbance=="High"],
dat$Plantago_abund[dat$Disturbance=="Low"],
dat$Plantago_abund[dat$Disturbance=="High"],
main="Test boxplot",
col=c("red","firebrick","blue","dodgerblue","green","darkgreen","yellow","gold"),
horizontal = TRUE,
notch = FALSE,
las=2,
names=c("Geranium,Low", "Geranium,High", "Tredescantia,Low","Tredescantia,High","Shepherds,Low", "Shepherds,High", "Plantago,Low","Plantago,High")
)
boxplot(dat$Geranium_cov[dat$Disturbance=="Low"],
dat$Geranium_cov[dat$Disturbance=="High"],
dat$Tredescantia_cov[dat$Disturbance=="Low"],
dat$Tredescantia_cov[dat$Disturbance=="High"],
dat$Shep_cov[dat$Disturbance=="Low"],
dat$Shep_cov[dat$Disturbance=="High"],
dat$Plantago_cov[dat$Disturbance=="Low"],
dat$Plantago_cov[dat$Disturbance=="High"],
main="Test boxplot",
col=c("pink","firebrick","blue","dodgerblue","green","darkgreen","yellow","gold"),
horizontal = TRUE,
notch = FALSE,
las=2,
names=c("Geranium,Low", "Geranium,High", "Tredescantia,Low","Tredescantia,High","Shepherds,Low", "Shepherds,High", "Plantago,Low","Plantago,High")
)
dat <- read.csv("Section_009_PlantData.csv")
View(dat)
dat[,1]
dat <- dat[,1:9]
colnames(dat)
library(tidyverse)
substr(dat$Group, star=1,stop=1)
dat$Group, <- substr(dat$Group, star=1,stop=1)
dat$Group <- substr(dat$Group, star=1,stop=1)
pivot_wider(dat, names_from=Species,  values_from=Abundance)
z <- pivot_wider(dat, names_from=Species,  values_from=Abundance)
View(z)
dat <- read.csv("Section_009_PlantData.csv")
dat <- dat[,1:9]
colnames(dat)
library(tidyverse)
dat$Group <- substr(dat$Group, star=1,stop=1)
z <- pivot_wider(dat, names_from=Species,  values_from=Abundance)
dat %>% dplyr::select(., Species, Abundance)
z <- dat %>% dplyr::select(., Species, Abundance) %>% pivot_wider(., names_from=Species,  values_from=Abundance)
dat %>% dplyr::select(., Species, Abundance) %>% pivot_wider(., names_from=Species,  values_from=Abundance)
dat %>% dplyr::select(., Species, Abundance)
z <- pivot_wider(dat, id_cols = Transect.Position,names_from=Species,  values_from=Abundance)
dat$ID <- paste(dat$Group, dat$Transect.Position)
dat$ID <- paste(dat$Group, dat$Transect.Position, sep="")
z <- pivot_wider(dat, id_cols = ID,names_from=Species,  values_from=Abundance)
colnames(dat)
z <- pivot_wider(dat, id_cols = ID, names_from=Species,  values_from=c(Abundance, x..Cover))
z <- pivot_wider(dat, id_cols = ID, names_from=Species,  values_from=c(Abundance, X..Cover))
plant_data <- pivot_wider(dat, id_cols = ID, names_from=Species,  values_from=c(Abundance, X..Cover))
colnames(dat)
dplyr::select(dat, ID, Canopy.Cover, Surface.Temp, Disturbance, PAR)
abiotic <- dplyr::select(dat, ID, Canopy.Cover, Surface.Temp, Disturbance, PAR)
View(abiotic)
abiotic %>% group_by(ID) %>% summarise(., Canopy.Cover=mean(Canopy.Cover))
abiotic_sum <- abiotic %>% group_by(ID) %>% summarise(., Canopy.Cover=mean(Canopy.Cover))
abiotic_sum <- abiotic %>% group_by(ID) %>% summarise(., Canopy.Cover=mean(Canopy.Cover), Surface.Temp=mean(Surface.Temp), Disturbance=mode(Disturbance), PAR=mean(PAR))
View(abiotic_sum)
abiotic_sum <- abiotic %>% group_by(ID) %>% summarise(., Canopy.Cover=mean(Canopy.Cover), Surface.Temp=mean(Surface.Temp), Disturbance=Disturbance[1], PAR=mean(PAR))
new_dat <- left_join(z, abiotic_sum)
View(new_dat)
substr(new_dat$ID,2,2)
new_dat$Transect <- as.numeric(substr(new_dat$ID,2,2))
new_dat$Transect <- as.numeric(substr(new_dat$ID,2,3))
write.csv(new_dat, "LongSection9dat.csv", row.names=FALSE)
load("~/Documents/Coding_Challenges/ENM.RData")
knitr::opts_chunk$set(echo = TRUE)
e.mx.l
knitr::opts_chunk$set(echo = TRUE)
disptype = "negativeComp"; n_plants = 5; n_animals = 5; dexpsim = dexpsim; r = 0.5; mup = 0.1; mua = 0.05; o = 0.1; lambda = log(1.5); K = 1000; e_thresh = 2; invade_size = 5; disprobmax = 0.2; num_timeSteps = 2000; invProb = 0.1
nsites <- 15
factor_sites <- as.factor(1:nsites) #This is important for the dispersal function down the road
coords <- data.frame(x=runif(nsites), y=runif(nsites))
eucdist <- dist(coords, diag=T, upper=T)
dexpdist <- dexp(eucdist, rate=10)
dexpsim <- 1/(1+as.matrix(dexpdist)) #Converting our distance matrix to a similarity score (easier for me to then turn into a pmf).
#Found this particular metric from here: https://stats.stackexchange.com/questions/158279/how-i-can-convert-distance-euclidean-to-similarity-score
disptype = "negativeComp"; n_plants = 5; n_animals = 5; dexpsim = dexpsim; r = 0.5; mup = 0.1; mua = 0.05; o = 0.1; lambda = log(1.5); K = 1000; e_thresh = 2; invade_size = 5; disprobmax = 0.2; num_timeSteps = 2000; invProb = 0.1
a_change
#Setting up initial plant pops
p_pops <- matrix(data=round(runif(nsites*n_plants, 1, 200)), nrow=nsites, ncol=n_plants) #now, our pops are a matrix instead of a vector in order to track across multiple sites
factor_sites <- as.factor(1:nsites)
set.seed(t+seedstart)
richness <- ncol(a_pops)+ncol(p_pops)
runDispersalSim <- function(X, disptype, nsites, dexpsim, disprobmax, n_plants, n_animals, r, mup, mua, o, lambda, K, e_thresh, invProb, invade_size, num_timeSteps=500, seedstart=0){
factor_sites <- as.factor(1:nsites)
#Setting up initial plant pops
p_pops <- matrix(data=round(runif(nsites*n_plants, 1, 200)), nrow=nsites, ncol=n_plants) #now, our pops are a matrix instead of a vector in order to track across multiple sites
p_traitM <- runif(n_plants, 0, 1)
p_traitV <- runif(n_plants, 0, .25)
#p_traitM <- c(0.25, 0.99, 0.5)
#p_traitV <- c(0.1, 0.1, 0.1) #All set to be the same in Becker paper
#Setting up initial animal pops
a_pops <- matrix(data=round(runif(nsites*n_animals, 1, 200)), nrow=nsites, ncol=n_animals)
a_traitM <- runif(n_animals, 0.05, 1)
a_traitV <- runif(n_animals, 0.05, .25)
#Add our function for finding overlap
min.f1f2 <- function(x, mu1, mu2, sd1, sd2) {
f1 <- dnorm(x, mean=mu1, sd=sd1)
f2 <- dnorm(x, mean=mu2, sd=sd2)
pmin(f1, f2)
}
#pops <- NULL
p_pops_output <- cbind(c(1:nsites), rep(0,nsites),p_pops) #Make output dataframe; first column is site, second is timestep; then populations
a_pops_output <- cbind(c(1:nsites), rep(0,nsites),a_pops) #Make output dataframe; first column is site, second is timestep; then populations
prior_richness <- 0 #setting as the starting point
int_fail <- FALSE #Dummy variable for integral try statement
lambda_fail <- FALSE #Dummy variable for rpois() projection
P_TraitVTot <- NULL #Create a bunch of empty objects so we can rbind weighted mean trait variance to later
A_TraitVTot <- NULL
P_WTraitMean_output <- NULL
A_WTraitMean_output <-  NULL
}
factor_sites <- as.factor(1:nsites)
#Setting up initial plant pops
p_pops <- matrix(data=round(runif(nsites*n_plants, 1, 200)), nrow=nsites, ncol=n_plants) #now, our pops are a matrix instead of a vector in order to track across multiple sites
p_traitM <- runif(n_plants, 0, 1)
p_traitV <- runif(n_plants, 0, .25)
#p_traitM <- c(0.25, 0.99, 0.5)
#p_traitV <- c(0.1, 0.1, 0.1) #All set to be the same in Becker paper
#Setting up initial animal pops
a_pops <- matrix(data=round(runif(nsites*n_animals, 1, 200)), nrow=nsites, ncol=n_animals)
a_traitM <- runif(n_animals, 0.05, 1)
a_traitV <- runif(n_animals, 0.05, .25)
#Add our function for finding overlap
min.f1f2 <- function(x, mu1, mu2, sd1, sd2) {
f1 <- dnorm(x, mean=mu1, sd=sd1)
f2 <- dnorm(x, mean=mu2, sd=sd2)
pmin(f1, f2)
}
#pops <- NULL
p_pops_output <- cbind(c(1:nsites), rep(0,nsites),p_pops) #Make output dataframe; first column is site, second is timestep; then populations
a_pops_output <- cbind(c(1:nsites), rep(0,nsites),a_pops) #Make output dataframe; first column is site, second is timestep; then populations
prior_richness <- 0 #setting as the starting point
int_fail <- FALSE #Dummy variable for integral try statement
lambda_fail <- FALSE #Dummy variable for rpois() projection
P_TraitVTot <- NULL #Create a bunch of empty objects so we can rbind weighted mean trait variance to later
A_TraitVTot <- NULL
P_WTraitMean_output <- NULL
A_WTraitMean_output <-  NULL
richness <- ncol(a_pops)+ncol(p_pops)
richness
if(richness > prior_richness){ #Check if we've updated the number of spp in the community
#if so, recalculate niche overlap and competition matrices
#print("recalculating")
alpha <- matrix(nrow=n_animals, ncol=n_plants) #Create an empty matrix for plant-pollinator partnerships
for(ia in 1:n_animals){
if(int_fail==TRUE){ #If we've come across an integration failure, break the loop
break()
}
for(ip in 1:n_plants){
temp <- try(integrate(min.f1f2, -Inf, Inf, mu1=p_traitM[ip], mu2=a_traitM[ia], sd1=p_traitV[ip], sd2=a_traitV[ia])$value) #Integrate our minimum equation over all numbers; output is the total area overlapping both curves, with max value of perfectly overlapping curves as 1
if(class(temp)=='try-error'){
int_fail <- TRUE
break()
}
alpha[ia, ip] <- temp
#print(paste("ia=", ia, "; ip=", ip, sep=""))
}
}
alpha[alpha<0.05] <- 0
u <- matrix(data=NA, nrow=n_plants, ncol=n_plants)
for(p1 in 1:n_plants){
if(int_fail==TRUE){ #If we've come across an integration failure, break the loop
break()
}
for(p2 in 1:n_plants){
temp <- try(integrate(min.f1f2, -Inf, Inf, mu1=p_traitM[p1], mu2=p_traitM[p2], sd1=p_traitV[p1], sd2=p_traitV[p2])$value) #Integrate our minimum equation over all numbers; output is the total area overlapping both curves, with max value of perfectly overlapping curves as 1
if(class(temp)=='try-error'){
int_fail <- TRUE
break()
}
u[p1, p2] <- temp
}
}
o <- matrix(data=NA, nrow=n_animals, ncol=n_animals) #Now, let's look at animal competition
for(ia in 1:n_animals){
if(int_fail==TRUE){ #If we've come across an integration failure, break the loop
break()
}
for(a2 in 1:n_animals){
temp <- try(integrate(min.f1f2, -Inf, Inf, mu1=a_traitM[a2], mu2=a_traitM[ia], sd1=a_traitV[a2], sd2=a_traitV[ia])$value) #Integrate our minimum equation over all numbers; output is the total area overlapping both curves, with max value of perfectly overlapping curves as 1
if(class(temp)=='try-error'){
int_fail <- TRUE
break()
}
o[ia, a2]<- temp
#print(paste("ia=", ia, "; ip=", ip, sep=""))
}
}
}
prior_richness <- richness
prior_richness
#Find out dpop/dt
a_change <- matrix(data=NA, nrow=nsites, ncol=n_animals)
for(n in 1:n_animals){
propOfplants <- 0
nums <- alpha[n,]*p_pops/K#[,site] What if we standardize plant species to K? This seems like it might have worked to fix my problem
for(i in 1:n_plants){
#Numerator-plant reward given by each focal pollinator
propOfplants <- propOfplants+nums[,i]/(r+sum(alpha[,i]*a_pops)) #Denominator-scaled by total available pollen
}
pollDeath <- mua
#print(propOfplants)
a_change[,n] <- lambda*((1-(o[,n]%*%t(a_pops))/K))*propOfplants# - pollDeath
} #Animal Growth Rate
a_change
propOfplants
propOfplants
propOfplants
sum(propOfplants)
propOfplants
alpha
alpha
rowSums(alpha)
colSums(alpha)
alpha
propOfplants
r+sum(alpha[,i]*a_pops
)
nums[,i]/(r+sum(alpha[,i]*a_pops
)
()
)
nums
sd(nums)
View(a_change)
knitr::opts_chunk$set(echo = TRUE)
flowdat <- read.csv(file="Flow_old.csv")[1:3,c(1:2,4:9)]
divdat <- read.csv(file="Diversity_old.csv")[,1:4]\
knitr::opts_chunk$set(echo = TRUE)
flowdat <- read.csv(file="Flow_old.csv")[1:3,c(1:2,4:9)]
divdat <- read.csv(file="Diversity_old.csv")[,1:4]
flowdat$time1 <- c(40.3, 9.2, 15.4)
flowdat$time2 <- c(40.3+runif(1,-2,2), 9.2 + +runif(1,-2,2), 15.4+runif(1,-2,2))
flowdat$time3 <- c(40.3+runif(1,-2,2), 9.2 + +runif(1,-2,2), 15.4+runif(1,-2,2))
flowdat$length <- c(5.3,4.8,4.2)
colnames(divdat) <- c("section", "site", "ID", "count")
flowdat$avg_depth <- (flowdat$Depth1_m + flowdat$Depth2_m + flowdat$Depth3_m)/5
flowdat$cross_area <- flowdat$avg_depth*flowdat$Width_m
flowdat$avg_time <- (flowdat$time1 + flowdat$time2+ flowdat$time3)/3
flowdat$velocity <- flowdat$length/flowdat$avg_time
flowdat$cms <- flowdat$velocity*flowdat$cross_area
flowdat$cfs <- flowdat$cms*35.314
flowdat$gpm <- flowdat$cfs*7.48*60
flowdat$gpd <-flowdat$gpm*60*24
library(tidyverse)
library(vegan)
divdat <- divdat %>% #The data we're going to summarize
group_by(site) %>% #We use group by to tell R we want a different summarize by site
mutate(., sumCount=sum(count)) #Mutate tells R to make a new column with whatever operation we want-here we sum the counts
View(divdat)
?vegan::diversity()
vegan::diversity(divdat$count)
vegan::diversity(divdat$count, index ="shannon")
vegan::diversity(divdat, index="shannon", groups=site)
divdat$relabundance <- divdat$count/divdat$sumCount
divdat$LNrelabund <- log(divdat$relabundance)
divdat$relabundance*divdat$LNrelabund
divdat$simp_cont <- divdat$relabundance*divdat$LNrelabund
divdat <- divdat %>% #The data we're going to summarize
group_by(site) %>% #We use group by to tell R we want a different summarize by site
mutate(., Simpsons=sum(simp_cont)) #Mutate tells R to make a new column with whatever operation we want-here we sum the counts
divdat$relabundSq <- divdat$relabundance^2
divdat$relabundSq
divdat <- divdat %>% #The data we're going to summarize
group_by(site) %>% #We use group by to tell R we want a different summarize by site
mutate(., Simpsons=-1*sum(simp_cont)) #Mutate tells R to make a new column with whatever operation we want-here we sum the counts
Simpsons <- divdat %>% #The data we're going to summarize
group_by(site) %>% #We use group by to tell R we want a different summarize by site
summarize(., Simpsons=-1*sum(simp_cont)) #Mutate tells R to make a new column with whatever operation we want-here we sum the counts
View(Simpsons)
Shannon <- divdat %>% #The data we're going to summarize
group_by(site) %>% #We use group by to tell R we want a different summarize by site
summarize(., Simpsons=1-*sum(relabundSq))
Shannon <- divdat %>% #The data we're going to summarize
group_by(site) %>% #We use group by to tell R we want a different summarize by site
summarize(., Simpsons=1-sum(relabundSq))
Shannon
Counts <- divdat %>% #The data we're going to summarize
group_by(site) %>% #We use group by to tell R we want a different summarize by site
summarise(., sumCount=sum(count)) #Mutate tells R to make a new column with whatever operation we want-here we sum the counts
Counts
170*2+130+50+100+25
170*2+130+50+100+30
155/650
170/650
130/650
130*5
50/650
100/650
30/650
26*2+20+12+20
50+20
25+20+25+7+4+15+5
155/650
170+130+170
470/650
160/650
140/650
25+21+25+7+4+15
+5
100/659
100/650
25/650
30/650
25+21+25+7+4+15+4
setwd("~/Documents/diseaseEcology")
blogdown::serve_site()
blogdown::serve_site()
blogdown::stop_server()
blogdown::serve_site()
servr::browse_last()
servr::browse_last()
servr::browse_last()
blogdown::stop_server()
blogdown::serve_site()
blogdown::stop_server()
blogdown::build_site()
blogdown::serve_site()
servr::browse_last()
servr::browse_last()
servr::browse_last()
blogdown::stop_server()
blogdown::build_site()
blogdown::serve_site()
blogdown::build_site()
blogdown::build_site()
blogdown::serve_site()
blogdown::build_site()
blogdown::serve_site()
blogdown::stop_server()
blogdown::stop_server()
blogdown::stop_server()
blogdown::stop_server()
blogdown::stop_server()
blogdown::stop_server()
blogdown::stop_server()
blogdown::stop_server()
blogdown::stop_server()
blogdown::stop_server()
blogdown::stop_server()
blogdown::stop_server()
blogdown::stop_server()
blogdown::stop_server()
blogdown::stop_server()
blogdown::stop_server()
blogdown::stop_server()
blogdown::stop_server()
blogdown::stop_server()
blogdown::stop_server()
blogdown::stop_server()
blogdown::stop_server()
blogdown::stop_server()
blogdown::stop_server()
blogdown::stop_server()
blogdown::stop_server()
blogdown::stop_server()
blogdown::stop_server()
blogdown::stop_server()
blogdown::stop_server()
blogdown::stop_server()
blogdown::serve_site()
